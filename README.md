# genai-ollama-chatbot

Simple GenAI chatbot using Ollama and Python.
It runs locally and allows users to ask questions and receive AI-generated answers.

# Tech Stack

Python
Ollama (local LLM runtime)
Mistral model and other models if required
Git and GitHub

# What This Project Does

Takes a user question from the terminal
Sends it to a local AI model
Returns an AI-generated response
Uses a system prompt to control AI behavior

# Verify Ollama Setup

Check that Ollama is running
Confirm the Mistral model is available
Test the model from the terminal

# Run the Application

Run the Python file
Start asking questions in the terminal
Type exit to stop the program

# Prompt Design Used in This Project

A system prompt is used to guide the AIâ€™s behavior.
Example:
The AI is instructed to behave like a senior Java Spring Boot developer
Responses are clear and concise
This helps generate consistent and relevant answers.

# Learning Outcomes

How GenAI applications work in real systems
How to communicate with LLMs using APIs
How prompt engineering affects AI output
